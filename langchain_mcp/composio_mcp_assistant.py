import getpass
import os
import asyncio
from langgraph.prebuilt import create_react_agent
from langchain.chat_models import init_chat_model
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain.schema import HumanMessage, AIMessage


if not os.environ.get("GOOGLE_API_KEY"):
    os.environ["GOOGLE_API_KEY"] = getpass.getpass("Enter API key for Google Gemini: ")


model = init_chat_model("gemini-2.5-flash", model_provider="google_genai")

client = MultiServerMCPClient(
    {
        "assistant": {
            "transport": "streamable_http",
            "url": "yor mcp server url",
        }
    }
)

async def main():
    tools = await client.get_tools()

    # ğŸ‘‡ Use system_message instead of custom ChatPromptTemplate
    agent = create_react_agent(
        tools=tools,
        model=model
    )

    print("ğŸš€ Multi-App AI Assistant Ready! Type 'exit' to quit.\n")

    chat_history = []

    while True:
        user_input = input("You: ")
        if user_input.lower() in ["exit", "quit"]:
            print("ğŸ‘‹ Goodbye!")
            break

        try:
            response = await agent.ainvoke({"messages": chat_history + [HumanMessage(content=user_input)]})

            # Extract output safely
            output = response.get("output", None)
            if not output and "messages" in response:
                output = response["messages"][-1].content

            print("ğŸ¤–:", output)

            # Save chat history
            chat_history.append(HumanMessage(content=user_input))
            chat_history.append(AIMessage(content=output))

        except Exception as e:
            print("âš ï¸ Error:", e)

if __name__ == "__main__":
    asyncio.run(main())
